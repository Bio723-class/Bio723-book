
# Data wrangling

In the real world you'll often create a data set (or be given one) in a format that is less than ideal for analysis.  This can happen for a number of reasons. For example, the data may have been recorded in a manner convenient for collection and visual inspection, but which does not work well for analysis and plotting.  Or the data may be an amalgamation of multiple experiments, in which each of the experimenters used slightly different naming conventions. Or the data may have been produced by an instrument that produces output with a fixed format.  Sometimes important experimental information is included in the column headers of a spreadsheet.

Whatever the case, we often find ourselves in the situation where we need to "wrangle" our data into a "tidy" format before we can proceed with visualization and analysis. The "R for Data Science" text discusses some desirable rules for "tidy" data in order to facilitate downstream analyses. These are:

  1. Each variable must have its own column.
  1. Each observation must have its own row.
  1. Each value must have its own cell.

In this lecture we're going to walk through an extended example of wrangling some data into a "tidy" format.

## Libraries


```{r}
library(magrittr)
library(stringr)
library(tidyverse)
library(cowplot)
```


## Data

To illustrate a data wrangling pipeline, we're going to use a gene expression microarray data set, based on the following paper:

* Spellman PT, et al. 1998. Comprehensive identification of cell cycle-regulated genes of the yeast Saccharomyces cerevisiae by microarray hybridization. Mol Biol Cell 9(12): 3273-97.

In this paper, Spellman and colleagues tried to identify all the genes in the yeast genome (>6000 genes) that exhibited oscillatory behaviors suggestive of cell cycle regulation.  To do so, they combined gene expression measurements from six different types of cell cycle synchronization experiments.

*Download the Spellman data to your filesystem* from [this link](https://github.com/Bio723-class/example-datasets/blob/master/spellman-combined.txt) (right-click the "Download" button and save to your Downloads folder or similar).  

I suggest that once you download the data, you open it in a spreadsheet program (e.g. Excel) or use the RStudio Data Viewer to get a sense of what the data looks like.

Let's load it into R, using the `read_tsv()` function, using the appropriate file path. 

```{r}
# the filepath may differ on your computer
spellman <- read_tsv("~/Downloads/spellman-combined.txt")
```

The initial dimenions of the data frame are:

```{r}
dim(spellman)
```


The six types of cell cycle synchronization experiments included in this data set are:

1. synchronization by alpha-factor = "alpha"
2. synchronization by cdc15 temperature sensitive mutants = "cdc15"
3. synchronization by cdc28 temperature sensitive mutants = "cdc28"
4. synchronization by elutration = "elu"
5. synchronization by cln3 mutatant strains = "cln3"
6. synchronization by clb2 mutant strains = "clb2"


## Renaming data frame columms 

Notice that when we imported the data we got a warning message: `Missing column names filled in: 'X1' [1]`.  In a data frame, every column must have a name. The first column of our data set did not have a name in the header, so `read_tsv` automatically gave it the name `X1`.  

Our first task is to give the first column a more meaningful name.  This column gives "systematic gene names" -- a standardized naming scheme for genes in the yeast genome.  We'll use `dplyr::rename` to rename `X1` to `gene`.  Note that `rename` can take multiple arguments if you need to rename multiple columns simultaneously.

```{r}
spellman.clean <- 
  spellman %>%
  rename(gene = X1)
```

Note the use of the compound assingment operator -- `%<>%` -- from the `magrittr` package, which we introduced in our last class session.


## Dropping unneeded columns

Take a look at the Spellman data again in your spreadsheet program (or the RStudio data viewer).  You'll notice there are some blank columns.  For example there is a column with the header "alpha" that has no entries.  These are simply visual organizing elements that the creator of the spreadsheet added to separate the different experiments that are included in the data set. 

We can use `dplyr::select()` to drop columns by prepending column names with the negative sign:

```{r}
# drop the alpha column keeping all others
spellman.clean %<>% 
  select(-alpha)  
```

Note that usually `select()`  keeps only the variables you specify.  However if the first expression is negative, `select` will instead automatically keep all variables, dropping only those you specify. 

### Finding all empty columns

In the example above, we looked at the data and saw that the "alpha" column was empty, and thus dropped it.  This worked  because there are only a modest number of columns in the data frame in it's initial form.  However, if our data frame contained thousands of columns, this "look and see" procedure would not be efficient.  Can we come up with a general solution for removing empty columns from a data frame?

When you load a data frame from a spreadsheet, empty cells are given the value `NA`.  In previous class sessions we were introduced to the function `is.na()` which tests each value in a vector or data frame for whether it's NA or not.  We can count NA values in a vector by summing the output of `is.na()`. Conversely we can count the number of "not NA" items by using the negation operator (`!`):

```{r}
# count number of NA values in the alpha0 column
sum(is.na(spellman$alpha0))

# count number of values that are NOT NA in alpha0
sum(!is.na(spellman$alpha0))
```

This seems like it should get us close to a solution but `sum(is.na(..))` when applied to a data frame counts NAs across the entire data frame, not column-by-column.

```{r}
# doesn't do what we hoped!
sum(is.na(spellman))
```

If we want sums of NAs by column, we instead use the `colSums()` function:

```{r}
# get number of NAs by column
colSums(is.na(spellman))
```

Columns with *all* missing values can be more conveniently found by asking for those columns where the number of "not missing" values is zero:

```{r}
# get names of all columns for which all rows are NA
# useing standard indexing
names(spellman)[colSums(!is.na(spellman)) == 0]
```

We can combine the `colSums(!is.na())` idiom with the `dplyr::select_if` function to quickly remove all empty columns as so:

```{r}
# this broke in dplyr 0.80 due to a bug (https://github.com/tidyverse/dplyr/issues/4213)
# supposedly a fix is on the way. In the iterim, a work around is included

#spellman.clean %<>%
  # keep ONLY the non-empty columns
  #select_if(colSums(!is.na(.)) > 0)  

not.all.na <- function(x) { 
  if (sum(!is.na(x)) > 0){
    return(TRUE)
    }
  else {
    return(FALSE)
    }
}

spellman.clean %<>%
  select_if(not.all.na)
```




### Dropping columns by matching names

Only two time points from the cln3 and clb2 experiments were reported in the original publication. Since complete time series are unavailable for these two experimental conditions we will drop them from further consideration.  

`select()` can be called be called with a number of "helper function" (`?select_helpers`). Here we'll illustrate the `matches()` helper function which matches column names to a "regular expression".  Regular expressions (also referred to as "regex" or "regexp") are a way of specifying patterns in strings. For the purposes of this document we'll illustrate  regexs by example; for a more detailed explanation of regular expressions see the the regex help(`?regex`) and the [Chapter on Strings in "R for Data Analysis"](http://r4ds.had.co.nz/strings.html): 

Let's see how to drop all the "cln3" and "clb2" columns from the data frame using `matches()`:

```{r}
spellman.clean %<>% 
  select(-matches("cln3")) %>%
  select(-matches("clb2"))
```

If we wanted we could have collapsed our two match statements into one as follows:

```{r}
spellman.clean %<>% 
  select(-matches("cln3|clb2"))
```

In this second example, the character "|" is specifing an OR match within the regular expression, so this regular expression matches column names that contain "cln3" OR "clb2".


## Merging data frames

Often you'll find yourself in the situation where you want to combine information from multiple data sources.  The usual requirement is that the data sources have one or more shared columns, that allow you to relate the entities or observations (rows) between the data sets. `dplyr` provides a variety of `join` functions to handle different data merging operators.

To illustrating merging or joining data sources, we'll add information about each genes "common name" and a description of the gene functions to our Spellman data set.  I've prepared a file with this info based on info I downloaded from the [Saccharomyces Genome Database](https://www.yeastgenome.org).


```{r}
gene.info <- read_csv("https://github.com/bio304-class/bio304-course-notes/raw/master/datasets/yeast-ORF-info.csv")
```

Having loaded the data, let's get a quick overview of it's structure:

```{r}
names(gene.info)
dim(gene.info)
head(gene.info)
```

In `gene.info`, the `ftr.name` column corresponds to the `gene` column in our Spellman data set.  The `std.name` column gives the "common" gene name (not every gene has a common name so there are lots of NAs).  The `description` column gives a brief textual description of what the gene product does.

To combine `spellmean.clean` with `gene.info` we use the `left_join` function defined in dplyr.  As noted in the description of the function, `left_join(x, y)` returns "all rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns." In addition, we have to specify the column to join by using the `by` argument to `left_join`.  

```{r}
spellman.merged <-
  left_join(spellman.clean, gene.info, by = c("gene" = "ftr.name"))
```

By default, the joined columns are merged at the end of the data frame, so we'll reorder variables to bring the `std.name` and `description` to the second and thirds columns, preserving the order of all the other colums.

```{r}
spellman.merged %<>%
  select(gene, std.name, description, everything())

spellman.merged
```


## Reshaping data with tidyr

The `tidyr` package provides functions for reshaping or tidying data frames.  `tidyr` is yet another component of the tidyverse, and thus was loaded by the `library(tidyverse)`. 

We're going to look at two functions `tidyr::gather()` and `tidyr::extract()`, and how they can be combined with now familiar `dplyr` functions we've seen previously.  The reading assignment for today's class session covers a variety of other functions defined in `tidyr`.
 
The Spellman data, as I provided it to you, is in what we would call "wide" format.  Each column (besides the `gene` column) corresponds to an experimental condition *and* time point.  For example, "alpha0" is the alpha-factor experiment at time point 0 mins; "alpha7" is the alpha-factor experiment at time point 7 mins, etc.  The cells within each column correspond to the expression of a corresponding gene (given by the first column which we renamed `gene`) in that particular experiment at that particular time point.

In every column (except "gene"), the cells represents the same abstract property of interest -- the expression of a gene of interest in a particular experiment/time point.  Our first task will be to rearrange our "wide" data frame that consists of many different columns representing gene expression into a "long" data frame with just a single column representing expression.  We'll also create a new column to keep track of  which experiment and time point the measurement came from.

### Wide to long conversions using `tidyr::gather`

`tidyr::gather()` takes multiple columns, and collapses them together into a smaller number of new columns.  When using `gather()` you give the names of the *new* columns to create, as well as the names of any existing columns `gather()` should *not* collect together.

Here we want to collapse all 73 or the expression columns -- "alpha0" to "elu390" -- into two columns: 1) a column to represent the expt/time point of the measurement, and 2) a column to represent the corresponding expression value.  The column we don't want to touch are the `gene`, `std.name`, and `description`.

```{r}
# convert "wide" data to "long"
spellman.long <-
  spellman.merged %>%
  gather(expt.and.time, expression, -gene, -std.name, -description)
```

Take a moment to look at the data in the "long format":

```{r}
head(spellman.long)
```

And compare the dimensions of the wide data to the new data:

```{r}
dim(spellman.merged)  # for comparison
dim(spellman.long)
```

As you see, we've gone from a data frame with `r nrow(spellman.merged)` rows and `r ncol(spellman.merged)` columns (wide format), to a new data frame with `r nrow(spellman.long)` rows and `r ncol(spellman.long)` columns (long format). 

### Extracting information from combined variables using `tidyr::extract`

The column `expt.and.time` violates one of our principles of tidy data: "Each variable must have its own column.".  This column conflates two different types of information -- the experiment type and the time point of the measurement.  Our next task is to split this information up into two new variables, which will help to facilitate downstream plotting and analysis.

One complicating factor is that the different experiments/time combinations have different naming conventions:

  * The "alpha" and "elu" experiments are of the form "alpha0", "alpha7", "elu0", "elu30", etc.  In this case, the first part of the string gives the experiment type (either alpha or elu) and the following digits give the time point. 

  * In the "cdc15" and "cdc28" experiments the convention is slightly different; they are of the form "cdc15_0", "cdc15_10", "cdc28_0", "cdc28_10", etc.  Here the part of the string before the underscore gives the experiment type, and the digits after the underscore give the time point.
  
Because of the differences in naming conventions, we will find it easiest to break up `spellman.long` into a series of sub-data sets corresponding to each experiment type in order to extract out the experiment and time information.  After processing each data subset separately, we will join the modified sub-data frames back together.

###  Subsetting rows 

Let's start by getting just the rows corresponding to the "alpha" experiment/times. Here we use `dplyr::filter` in combination with `stringr::str_detect` to get all those rows in which the `expt.and.time` variable contains the string "alpha".

```{r}
alpha.long <- 
  spellman.long %>%
  filter(str_detect(expt.and.time, "alpha"))

# look at the new data frame
dim(alpha.long)
head(alpha.long, n = 10)
```

### Splitting columns

Having subsetted the data, we can now split `expt.and.time` into two new variables -- `expt` and `time`.  To do this we use `tidyr::extract`.


```{r}
alpha.long %<>% 
  tidyr::extract(expt.and.time,     # column we're extracting from
                 c("expt", "time"), # new columns we're creating
                 regex="(alpha)([[:digit:]]+)",  # regexp (see below)
                 convert=TRUE)      # automatically convert column types

# NOTE: I'm being explict about saying tidyr::extract because the
# magrittr package defines a different extract function
```


Let's take a moment to look at the `regex` argument to `extract` --  `regex="(alpha)([[:digit:]]+)"`.  The regex is specified as a character string.  Each part we want to match *and* extract is surround by parentheses.  In this case we have two sets of parentheses corresponding to the two matches we want to make.  The first part of the regex is `(alpha)`; here we're looking to make an exact match to the string "alpha".  The second part of the regex reads `([[:digit:]]+)`. `[[:digit:]]` indicates we're looking for a numeric digit.  The `+` after `[[:digit:]]` indicates that we want to match  *one or more* digits (i.e. to get a match we need to find at least one digit, but more than one digit should also be a match).


Let's take a look at the new version of `alpha.long` following application of `extract`:

```{r}
head(alpha.long, n = 10)
```

Notice our two new variables, both of which have appropriate types!

A data frame for the elutriation data can be created similarly:

```{r}
elu.long <-
  spellman.long %>%
  filter(str_detect(expt.and.time, "elu")) %>%
  tidyr::extract(expt.and.time,     # column we're extracting from
                 c("expt", "time"), # new columns we're creating
                 regex="(elu)([[:digit:]]+)",  # regexp (see below)
                 convert=TRUE)      # automatically convert column types
```


#### A fancier regex for the cdc experiments

Now let's process the cdc experiments (cdc15 and cdc28).  As before we extract the corresponding rows of the data frame using `filter` and `str_detect`.  We then split `expt.and.time` using `tidyr::extract`.  In this case we carry out the two steps in a single code block using pipes:

```{r}
cdc.long <- 
  spellman.long %>%
  # both cdc15 and cdc28 contain "cdc" as a sub-string
  filter(str_detect(expt.and.time, "cdc")) %>%
  tidyr::extract(expt.and.time, 
                 c("expt", "time"), 
                 regex="(cdc15|cdc28)_([[:digit:]]+)", # note the fancier regex
                 convert=TRUE)
```

The regex -- `"(cdc15|cdc28)_([[:digit:]]+)"` -- is slightly fancier in this example. As before there are two parts we're extracting: `(cdc15|cdc28)` and `([[:digit:]]+)`.  The first parenthesized regexp is an "OR" -- i.e. match "cdc15" *or* "cdc28".  The second parenthesized regexp is the same as we saw previously.  Separating the two parenthesized regexps is an underscore (`_`).  The underscore isn't parenthesized because we only want to use it to make a match *not* to extract the corresponding match.


### Combining data frames

If you have two or more data frames with identical columns, the rows of the data frames can be combined into a single data frame using `rbind` (defined in the `base` package).  For example, to reassemble the `alpha.long`, `elu.long`, and `cdc.long` data frames into a single data frame we do:

```{r}
spellman.final <- rbind(alpha.long, elu.long, cdc.long)

# check the dimensions of the new data frame
dim(spellman.final)
```

### Sorting data frame rows

Currently the `spellman.final` data frame is sorted by time point and experiment.  

```{r}
head(spellman.final, n = 10)
```

It might be useful instead to sort by gene and experiment.  To do this we can use `dplyr::arrange`:

```{r}
spellman.final %<>%
  arrange(gene, expt)

# look again at the rearranged data
head(spellman.final, n = 10)
```

## Using your tidy data

Whew -- that was a fair amount of work to tidy our data!  But having done so we can now carry out a wide variety of very powerful analyses.  

### Visualizing gene expression time series

Let's start by walking through a series of visualizations of gene expression time series.  Each plot will show the expression of one or more genes, at different time points, in one or more experimental conditions. Our initial visualizations exploit the "long" versions of the tidy data.

First a single gene in a single experimental condition:

```{r}
spellman.final %>%
  filter(expt == "alpha", gene == "YAL022C") %>%
  ggplot(aes(x = time, y = expression)) + 
    geom_line() + 
    labs(x = "Time (mins)", y = "Expression of YAL022C")
```

We can easily modify the above code block to visualize the expression of multiple genes of interest:

```{r}
genes.of.interest <- c("YAL022C", "YAR018C", "YGR188C")

spellman.final %>%
  filter(gene %in% genes.of.interest, expt == "alpha") %>%
  ggplot(aes(x = time, y = expression, color = gene)) +
    geom_line() + 
    labs(x = "Time (mins)", y = "Normalized expression",
         title = "Expression of multiple genes\nfollowing synchronization by alpha factor")
```

By employing `facet_wrap()` we can visualize the relationship between this set of genes in each of the experiment types:

```{r}
spellman.final %>%
  filter(gene %in% genes.of.interest) %>%
  ggplot(aes(x = time, y = expression, color = gene)) +
    geom_line() + 
    facet_wrap(~ expt) +
    labs(x = "Time (mins)", y = "Normalized expression",
         title = "Expression of Multiple Genes\nAcross experiments") 
```

The different experimental treatments were carried out for varying lengths of time due to the differences in their physiological effects. Plotting them all on the same time scale can obscure that patterns of oscillation we might be interested in, so let's modify our code block so that plots that share the same y-axis, but have differently scaled x-axes.

```{r}
spellman.final %>%
  filter(gene %in% genes.of.interest) %>%
  ggplot(aes(x = time, y = expression, color = gene)) +
    geom_line() + 
    facet_wrap(~ expt, scales = "free_x") +
    labs(x = "Time (mins)", y = "Normalized expression",
         title = "Expression of Multiple Genes\nAcross experiments") 
```


### Finding the most variable genes

When dealing with vary large data sets, one ad hoc filtering criteria that is often employed is to focus on those variables that exhibit that greatest variation (variation is measure of the spread of data; we will give a precise definition in a later lecture).  To do this, we first need to order our variables (genes) by their variation.  Let's see how we can accomplish this using our long data frame:

```{r}
by.variance <-
  spellman.final %>%
  group_by(gene) %>% 
  summarize(expression.var = var(expression, na.rm = TRUE)) %>%
  arrange(desc(expression.var))

head(by.variance)
```

The code above calculates the variance of each gene but ignores the fact that we have different experimental conditions.  To take into account the experimental design of the data at hand, let's calculate the average variance across the experimental conditions:

```{r}
by.avg.variance <-
  spellman.final %>%
  group_by(gene, expt) %>% 
  summarize(expression.var = var(expression, na.rm = TRUE)) %>%
  group_by(gene) %>%
  summarize(avg.expression.var = mean(expression.var)) %>%
  arrange(desc(avg.expression.var))

head(by.avg.variance)
```

Based on the average experession variance across experimental conditions, let's get the names of the 1000 most variable genes:

```{r}
top.genes.1k <- by.avg.variance[1:1000,]$gene

head(top.genes.1k)
```





### Heat maps

In our prior visualizations we've used line plots to depict how gene expression changes over time.  For example here are line plots for 15 genes in the data set, in the cdc28 experimental conditions:

```{r, warning=FALSE, message=FALSE}
genes.of.interest <- c("YHR084W", "YBR083W", "YPL049C", "YDR480W",
                       "YGR040W", "YLR229C", "YDL159W", "YBL016W",
                       "YDR103W", "YJL157C", "YNL271C", "YDR461W",
                       "YHL007C", "YHR005C", "YJR086W")

spellman.final %>%
  filter(expt == "cdc28", gene %in% genes.of.interest) %>%
  ggplot(aes(x = time, y = expression, color=gene)) + 
    geom_line() +
    labs(x = "Time (min)", y = "Expression")
```

Even with just 10 overlapping line plots, this figure is quite busy and it's hard to make out the individual behavior of each gene.

An alternative approach to depicting such data is a "heat map" which depicts the same information in a grid like form, with the expression values indicated by color.  Heat maps are good for depicting large amounts of data and providing a coarse "10,000 foot view".  We can create a heat map using `geom_tile` as follows:

```{r}
spellman.final %>%
  filter(expt == "cdc28", gene %in% genes.of.interest) %>%
  ggplot(aes(x = time, y = gene)) + 
    geom_tile(aes(fill = expression)) +
    xlab("Time (mins)")
```

This figure represents the same information as our line plot, but now there is row for each gene, and the expression of that gene at a given time point is represented by  color (scale given on the right). Missing data is shown as gray boxes.  Unfortunately, the default color scale used by ggplot is a very subtle gradient from light to dark blue.  This make it hard to distinguish patterns of change. Let's now see how we can improve that.

#### Better color schemes with RColorBrewer

The `RColorBrewer` packages provides nice color schemes that are useful for creating heat maps. RColorBrewer defines a set of color palettes that have been optimized for color discrimination, many of which are color blind friendly, etc.  Install the RColorBrewer package using the command line or the RStudio GUI.

Once you've installed the RColorBrewer package you can see the available color palettes as so:

```{r}
library(RColorBrewer)

# show representations of the palettes
par(cex = 0.5) # reduce size of text in the following plot
display.brewer.all()  
```

We'll use the Red-to-Blue ("RdBu") color scheme defined in RColorBrewer, however we'll reverse the scheme so blues represent low expression and reds represent high expression.  We'll divide the range of color values into 9 discrete bins.

```{r}
# displays the RdBu color scheme divided into a palette of 9 colors
display.brewer.pal(9, "RdBu")  

# assign the reversed (blue to red) RdBu palette
color.scheme <- rev(brewer.pal(9,"RdBu"))
```

Now let's regenerate the heat map we created previously with this new color scheme. To do this we specify a gradient color scale using the `scale_fill_gradientn()` function from ggplot.  In addition to specifying the color scale, we also constrain the limits of the scale to insure it's symmetric about zero.

```{r}
spellman.final %>%
  filter(expt == "cdc28", gene %in% genes.of.interest) %>%
  ggplot(aes(x = time, y = gene)) + 
    geom_tile(aes(fill = expression)) +
    scale_fill_gradientn(colors=color.scheme,
                         limits = c(-2.5, 2.5)) + 
    xlab("Time (mins)")
```

#### Looking for patterns using sorted data and heat maps

The real power of heat maps becomes apparent when you you rearrange the rows of the heat map to emphasize patterns of interest.

For example, let's create a heat map in which we sort genes by the time of their maximal expression.  This is one way to identify genes that reach their peak expression at similar times, which is one criteria one might use to identify genes acting in concert. 

For simplicities sake we will restrict our attention to the cdc28 experiment, and only consider the 1000 most variables genes with no more than one missing observation in this experimental condition.

```{r}
cdc28 <-
  spellman.final %>%
  filter(expt == "cdc28") %>%
  group_by(gene) %>%
  filter(sum(is.na(expression)) <= 1) %>%
  ungroup   # removes grouping information from data frame

top1k.genes <-
  cdc28 %>%
  group_by(gene) %>%
  summarize(expression.var = var(expression, na.rm = TRUE)) %>%
  arrange(desc(expression.var)) %$%
  gene[1:1000]
    
top1k.cdc28 <- 
  cdc28 %>%
  filter(gene %in% top1k.genes)
```


To find the time of maximum expression we'll employ the function `which.max` (`which.min`), which finds the index of the maximum (minimum) element of a vector.  For example to find the index of the maximum expression measurement for YAR018C we could do:

```{r}
top1k.cdc28 %>%
  filter(gene == "YAR018C") %$%  # note the exposition pipe operator!
  which.max(expression)
```

From the code above we find that the index of the observation at which YAR018C is maximal at 8.  To get the corresponding time point we can do something like this:


```{r}
top1k.cdc28 %>%
  filter(gene == "YAR018C") %$%  # again note the exposition pipe operator!
  time[which.max(expression)]


```

Thus YAR018C expression peaks at 70 minutes in the cdc28 experiment.

To find the index of maximal expression of all genes we can apply the `dplyr::group_by()` and `dplyr::summarize()` functions

```{r}
peak.expression.cdc28 <- 
  top1k.cdc28 %>% 
  group_by(gene) %>% 
  summarise(peak = which.max(expression))

head(peak.expression.cdc28)
```

Let's sort the order of genes by their peak expression:

```{r}
peak.expression.cdc28 %<>% arrange(peak)
```

We can then generate a heatmap where we sort the rows (genes) of the heatmap by their time of peak expression.  We introduce a new geom -- `geom_raster` -- which is like `geom_tile` but better suited for large data (hundreds to thousands of rows)  

The explicit sorting of the data by peak expression is carried out in the call to `scale_y_discrete()` where the limits (and order) of this axis are set with the `limits` argument (see `scale_y_discrete` and `discrete_scale` in the ggplot2 docs).

```{r, fig.height = 8, fig.width = 6, fig.cap = "A Heatmap showing genes in the cdc28 experiment, sorted by peak expression", fig.align="center"}

# we reverse the ordering because geom_raster (and geom_tile)
# draw from the bottom row up, whereas we want to depict the
# earliest peaking genes at the top of the figure
gene.ordering <- rev(peak.expression.cdc28$gene)

top1k.cdc28 %>%
  ggplot(aes(x = time, y = gene)) +
  geom_raster(aes(fill = expression)) +  # 
  scale_fill_gradientn(limits=c(-2.5, 2.5),
                       colors=color.scheme) +
  scale_y_discrete(limits=gene.ordering) + 
  labs(x = "Time (mins)", y = "Genes", 
       title = "1000 most variable genes",
       subtitle = "Sorted by time of peak expression") +
  # the following line suppresses tick and labels on y-axis
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

The brightest red regions in each row of the heat map correspond to the times of peak expression, and the sorting of the rows helps to highlight those gene whose peak expression times are similar.  





## Long-to-wide conversion using `tidyr::spread`

Our long data frame consists of four variables -- `gene`, `expt`, `time`, and `expression`.  This made it easy to create visualizations and summaries where time and expression were the primaries variables of interest, and gene and experiment type were categories we could condition on.

To facilitate analyses that emphasize comparison between genes, we want to create a new data frame in which each gene is itself treated as a variable of interest along with time, and experiment type remains a categorical variable.  In this new data frame rather than just four columns in our data frame, we'll have several thousand columns -- one for each gene.

To accomplish this reshaping of data, we'll use the function `tidyr::spread()`.  `tidyr::spread()` is the inverse of `tidyr::gather()`.  `gather()` took multiple columns and collapsed them together into a smaller number of new columns.  The `tidyr` documentation calls this "collapsing into key-value pairs".  By contrast, `spread()` creates new columns by spreading "key-value pairs" (a column representing the "keys" and a column reprsenting the "values") into multiple columns.  

Here let's use `spread()` to use the gene names (the "key") and expression measures (the "values") to create a new data frame where the genes are the primary variables (columns) of the data. 

```{r}
spellman.wide <-
  spellman.final %>%
  select(-std.name, -description) %>% # drop unneeded columns
  spread(gene, expression)
```

Now let's examine the dimensions of this wide version of the data:

```{r}
dim(spellman.wide)
```

And here's a visual view of the first few rows and columns of the wide data:

```{r}
spellman.wide[1:5, 1:8]
```

From this view we infer that the rows of the data set represent the various combination of experimental condition and time points, and the  columns represents the 6178 genes in the data set plus the two columns for `expt` and `time`.


## Exploring bivariate relationships using "wide" data

The "long" version of our data frame proved useful for exploring how gene expression changed over time.  By contrast, our "wide" data frame is more convient for exploring how pairs of genes covary together.  For example, we can generate bivariate scatter plots depicting the relationship between two genes of interest:

```{r}
two.gene.plot <-
  spellman.wide %>%
  filter(!is.na(YAR018C) & !is.na(YAL022C)) %>%  # remove NAs
  ggplot(aes(x = YAR018C, y = YAL022C)) +
  geom_point() + 
  theme(aspect.ratio = 1)

two.gene.plot
```

From the scatter plot we infer that the two genes are "positively correlated" with each other, meaning that high values of one tend to be associated with high values of the other (and the same for low values).

We can easily extend this visualization to facet the plot based on the experimental conditions:

```{r}
two.gene.plot + facet_wrap(~expt, nrow = 2, ncol = 2) 
```

A statistic we use to measure the degree of association between pairs of continuous variables is called the "correlation coefficient". Briefly, correlation is a measure of linear association between a pair of variables, and ranges from -1 to 1. A value near zero indicates the variables are uncorrelated (no linear association), while values approaching +1 indicate a strong positive association (the variables tend to get bigger or smaller together) while values near -1 indicate strong negative association (when one variable is larger, the other tends to be small).  

Let's calculate the correlation between YAR018C and YAL022C:

```{r}
spellman.wide %>%
  filter(!is.na(YAR018C) & !is.na(YAL022C)) %>%  
  summarize(cor = cor(YAR018C, YAL022C))
```

The value of the correlation coefficient for YAR018C and YAL022C, ~0.69, indicates a fairly strong association between the two genes.

As we did for our visualization, we can also calculate the correlation coefficients for the two genes under each experimental condition:

```{r}
spellman.wide %>%
  filter(!is.na(YAR018C) & !is.na(YAL022C)) %>%  
  group_by(expt) %>%
  summarize(cor = cor(YAR018C, YAL022C))
```

This table suggests that the the strength of correlation between YAR018C and YAL022C may depend on the experimental conditions, with the highest correlations evident in the cdc28 and elu experiments.

### Large scale patterns of correlations

Now we'll move from considering the correlation between two specific genes to looking at the correlation between many pairs of genes.  As we did in the previous section, we'll focus specifically onthe 1000 most variable genes in the cdc28 experiment.


First we filter our wide data set to only consider the cdc28 experiment and those genes in the top 1000 most variable genes in cdc28:

```{r}
top1k.cdc28.wide <- 
  top1k.cdc28 %>%
  select(-std.name, -description) %>%
  spread(gene, expression)
```

With this restricted data set, we can then calculate the correlations between every pair of genes as follows:

```{r}
cdc28.correlations <- 
  top1k.cdc28.wide %>%
  select(-expt, -time)  %>% # drop expt and time
  cor(use = "pairwise.complete.obs")
```

The argument `use = "pairwise.complete.obs"` tells the correlation function that for each pair of genes to use only the pariwse where there is a value for both genes (i.e. neither one can be NA).  

Given $n$ genes, there are $n \times n$ pairs of correlations, as seen by the dimensions of the correlation matrix.

```{r}
dim(cdc28.correlations)
```

To get the correlations with a gene of interest, we can index with the gene name on the rows of the correlation matrix. For example, to get the correlations between the gene YAR018C and the first 10 genes in the top 1000 set:

```{r}
cdc28.correlations["YAR018C",1:10]  
```

In the next statement we extract the names of the genes that have correlations with YAR018C greater than 0.6.   First we test genes to see if they have a correlation with YAR018C greater than 0.6, which returns a vector of TRUE or FALSE values.  This vector of Boolean values is than used to index into the rownames of the correlation matrix, pulling out the gene names where the statement was true.

```{r}
pos.corr.YAR018C <- rownames(cdc28.correlations)[cdc28.correlations["YAR018C",] > 0.6]
length(pos.corr.YAR018C)
```

We then return to our long data to show this set of genes that are strongly positively correlated with YAR018C.  

```{r}
top1k.cdc28 %>%
  filter(gene %in% pos.corr.YAR018C) %>%
  ggplot(aes(x = time, y = expression, group = gene)) + 
    geom_line(alpha = 0.33) +
    theme(legend.position = "none")
```

As is expected, genes with strong positive correlations with YAR018C. show similar temporal patterns with YAR018C. 


We can similarly filter for genes that have negative correlations with YAR018C. 

```{r}
neg.corr.YAR018C <- colnames(cdc28.correlations)[cdc28.correlations["YAR018C",] <= -0.6]
```

As before we generate a line plot showing these genes:

```{r}
top1k.cdc28 %>%
  filter(gene %in% neg.corr.YAR018C) %>%
  ggplot(aes(x = time, y = expression, group = gene)) +
    geom_line(alpha = 0.33) +
    theme(legend.position = "none")  
```


### Adding new columns and combining filtered data frames

Now let's create a new data frame by: 1) filtering on our list of genes that have strong positive and negative correlations with YAR018C; and 2) creating a new variable, "corr.with.YAR018C", which indicates the sign of the correlation.  We'll use this new variable to group genes when we create the plot.

```{r}
pos.corr.df <- 
  top1k.cdc28 %>%
  filter(gene %in% pos.corr.YAR018C) %>%
  mutate(corr.with.YAR018C = "positive")

neg.corr.df <- 
  top1k.cdc28 %>%
  filter(gene %in% neg.corr.YAR018C) %>%
  mutate(corr.with.YAR018C = "negative")

combined.pos.neg <- rbind(pos.corr.df, neg.corr.df)
```

Finally, we plot the data, colored according to the correlation with YAR018C: 

```{r, fig.width = 8, fig.height=6, warning=FALSE}
ggplot(combined.pos.neg, 
       aes(x = time, y = expression,  group = gene,
           color = corr.with.YAR018C)) + 
  geom_line(alpha=0.25) + 
  geom_line(aes(x = time, y = expression),
            data = filter(top1k.cdc28, gene == "YAR018C"),
            color = "DarkRed", size = 2,alpha=0.5) +
  # changes legend title and values for color sclae
  scale_color_manual(name = "Correlation with YAR018C",
                       values = c("blue", "red"))  + 
  labs(title = "Genes strongly positively and negatively correlated with YAR018C",
       subtitle = "YAR018C shown in dark red",
       x = "Time (mins)", y = "Expression")
```



### A heat mapped sorted by correlations

In our previous heat map example figure, we sorted genes according to peak expression.  Now let's generate a heat map for the genes that are strongly correlated (both positive and negative) with YAR018C.  We will sort the genes according to the sign of their correlation.

```{r, fig.width=12, fig.height=12}
# re-factor gene names so positive and negative genes are spatially distinct in plot
combined.pos.neg$gene <- 
  factor(combined.pos.neg$gene, 
         levels = c(pos.corr.YAR018C, neg.corr.YAR018C))

combined.pos.neg %>%
  ggplot(aes(x = time, y = gene)) + 
    geom_tile(aes(fill = expression)) +
    scale_fill_gradientn(colors=color.scheme) + 
    xlab("Time (mins)")
```

The breakpoint between the positively and negatively correlated sets of genes is quite obvious in this figure.

### A "fancy" figure

Recall that we introduced the `cowplot` library in Chapter 6, as a way to combine different ggplot outputs into subfigures such as you might find in a published paper.  Here we'll make further use cowplot to combine our heat map and line plot visualizations of genes that covary with YAR018C.

```{r, message=FALSE}
library(cowplot)
```

cowplot's `draw_plot()` function allows us to place plots at arbitrary locations and with arbitrary sizes onto the canvas. The coordinates of the canvas  run from 0 to 1, and the point (0, 0) is in the lower left corner of the canvas. We'll use `draw_plot` to draw a complex figure with a heatmap on the left, and two smaller line plots on the right.

```{r}
pos.corr.lineplot <-  
  combined.pos.neg %>%
  filter(gene %in% pos.corr.YAR018C) %>%
  ggplot(aes(x = time, y = expression, group = gene)) +
    geom_line(alpha = 0.33, color = 'red') +
    labs(x = "Time (mins)", y = "Expression", 
      title = "Genes Positively correlated\nwith YAR018C")

neg.corr.lineplot <- 
  combined.pos.neg %>%
  filter(gene %in% neg.corr.YAR018C) %>%
  ggplot(aes(x = time, y = expression, group = gene)) +
    geom_line(alpha = 0.33, color = 'blue') +
    labs(x = "Time (mins)", y = "Expression", 
      title = "Genes negatively correlated\nwith YAR018C")


heat.map <- 
  ggplot(combined.pos.neg, aes(x = time, y = gene)) + 
    geom_tile(aes(fill = expression)) +
    scale_fill_gradientn(colors=color.scheme) + 
    labs(x = "Time (mins)", y = "Gene") +
    theme(legend.position = "none")
```


The coordinates of the canvas  run from 0 to 1, and the point (0, 0) is in the lower left corner of the canvas. We'll use `draw_plot` to draw a complex figure with a heatmap on the left, and two smaller line plots on the right.

I determined the coordinates below by experimentation to create a visually pleasing layout.

```{r, fig.width = 16, fig.height = 12}
fancy.plot <- ggdraw() + 
  draw_plot(heat.map, 0, 0, width = 0.6) + 
  draw_plot(neg.corr.lineplot, 0.6, 0.5, width = 0.4, height = 0.5) +
  draw_plot(pos.corr.lineplot, 0.6, 0,   width = 0.4, height = 0.5) + 
  draw_plot_label(c("A", "B", "C"), c(0, 0.6, 0.6), c(1, 1, 0.5), size = 15)

fancy.plot
```

